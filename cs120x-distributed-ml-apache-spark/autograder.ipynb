{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<a rel=\"license\" href=\"http://creativecommons.org/licenses/by-nc-nd/4.0/\"><img alt=\"Creative Commons License\" style=\"border-width:0\" src=\"https://i.creativecommons.org/l/by-nc-nd/4.0/88x31.png\" /></a><br />This work is licensed under a <a rel=\"license\" href=\"http://creativecommons.org/licenses/by-nc-nd/4.0/\">Creative Commons Attribution-NonCommercial-NoDerivatives 4.0 International License</a>."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# Verify that the username is set\n",
    "try:\n",
    "  print \"Your username is \" + username\n",
    "except NameError:\n",
    "  assert False, \"Your username is not set. Please check that you set your username in the previous cell and you exectuted the cell using SHIFT-ENTER.\"\n",
    "  \n",
    "from autograder import autograder\n",
    "signup = autograder()\n",
    "try:\n",
    "  print \"Your private token is \" + private_token\n",
    "except NameError:\n",
    "  print signup.signup(username)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Restart your cluster\n",
    "\n",
    "* Click on \"Run All\" to run all of the cells in your LAB notebook.\n",
    "* Publish your LAB notebook by clicking on the \"Publish\" button at the top of your LAB notebook."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Change `notebook_url` and `lab` variables"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "notebook_url = \"https://databricks-prod-cloudfront.cloud.databricks.com/public/\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# Set lab variable (e.g., lab = \"CS105x-lab0\")\n",
    "# lab = \"CS105x-lab2\"\n",
    "# lab = \"CS120x-lab0\"\n",
    "lab = \"CS120x-lab1a\""
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Re-run the AUTOGRADER notebook"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "client = autograder(username, private_token)\n",
    "client.submit(lab, notebook_url)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "stop"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Check the status of the course autograder queue"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# Re-run this cell to see the autograder queue status\n",
    "import json\n",
    "(result,queue) = client.get_queue_status()\n",
    "if (queue == []):\n",
    "  print \"No submisions for %s found in autograder queue. Proceed to Part 5.\" % username\n",
    "else:\n",
    "  # convert result to a Spark DataFrame\n",
    "  df_queue = sqlContext.jsonRDD(sc.parallelize([json.dumps(item) for item in queue]))\n",
    "  display(df_queue['submission_timestamp','grading_status','lab','username'])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Get your submission ID for submitting on the edX course website"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "import json\n",
    "(result,submission_list) = client.get_submission_list(lab)\n",
    "if (submission_list == []):\n",
    "  print \"No submisions for %s found in autograder queue for lab %s\" % (username, lab)\n",
    "else:\n",
    "  # convert result to a Spark DataFrame\n",
    "  df_submission_list = sqlContext.jsonRDD(sc.parallelize([json.dumps(item) for item in submission_list]))\n",
    "  display(df_submission_list['submission_timestamp','grade','submission_id','lab','username'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "submission_id = (df_submission_list\n",
    "                 .select('submission_id')\n",
    "                 .sort('grade', ascending = False)\n",
    "                 .first()['submission_id'])\n",
    "\n",
    "print(submission_id)\n",
    "\n",
    "(result,submission_detail) = client.get_submission_detail(submission_id)\n",
    "print submission_detail['autograder_results']\n",
    "print submission_detail['grade']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.5.2"
  },
  "name": "autograder",
  "notebookId": 1028852224615792
 },
 "nbformat": 4,
 "nbformat_minor": 0
}
